Lecture Summary: CS 120 - Privacy, Anonymization, and K-Anonymity (April 21, 2025)

ğŸ“… Announcements
â€¢	This Friday (April 25): No in-person class. Instead, students will be assigned a short reading and comment activity.
â€¢	From next Monday (April 28) onward: All remaining sessions will be online only.
â€¢	Office hours will still be available virtually.
â€¢	Final exam will be online.
â€¢	Position Paper 3 is now available: it is an anti-position paper, where students will rebut their own earlier argument.
â€¢	Reminder: If you do not consent to AI-assisted grading, write â€œI do not consent to AI-assisted gradingâ€ at the top of your submission.

â¸»

ğŸ” Privacy, Anonymity, and Re-identification

Personally Identifiable Information (PII):
â€¢	Any piece of information that can be linked to a specific individual (e.g., name, date of birth, zip code, gender, address).
â€¢	Even if names are removed, individuals can still be re-identified by combining other attributes.

Latanya Sweeneyâ€™s Research:
â€¢	Demonstrated that even â€œanonymizedâ€ datasets can be de-anonymized.
â€¢	In 1997, showed that 87% of the U.S. population could be uniquely identified using just zip code, date of birth, and sex.
â€¢	Re-identified the Massachusetts governorâ€™s hospital records by cross-referencing â€œanonymizedâ€ health data with voter rolls.

â¸»

ğŸ”¢ K-Anonymity

Definition:

A dataset is said to have k-anonymity if every record is indistinguishable from at least (k-1) others based on a set of quasi-identifiers (like age, gender, zip code).

Example:

If three people in a dataset are all 29 years old, live in the same zip code, and have different favorite cakes, an attacker cannot tell which person corresponds to which cake. This is called 3-anonymity.

Techniques:
1.	Suppression â€“ Replace specific values with placeholders (e.g., â€˜*â€™) to prevent re-identification.
2.	Generalization â€“ Convert specific values into broader categories (e.g., age 27 becomes â€œ21â€“30â€).

Privacy through Groups:
â€¢	The greater the value of k, the more protected each individualâ€™s identity is.
â€¢	Protects against uniqueness-based re-identification.

â¸»

ğŸ§ª In-Class Activity: Anonymizing Dummy Patient Data

Students were given a CSV file containing fictional patient data including:
â€¢	Name, Age, Sex, Height, Weight, Diagnosis, Religion, etc.

Objective:

Apply anonymization techniques to prepare the data for safe publication.

Student Observations:
â€¢	Delete names and replace with patient IDs.
â€¢	Bucket ages into ranges (e.g., 18â€“25, 26â€“35).
â€¢	Convert weight/height into bins.
â€¢	Collapse religious categories into broader groups (e.g., Christian, Muslim, Other).
â€¢	Suppress rare diagnoses to prevent uniqueness.

Instructor Demonstration:
â€¢	Created master copy of data before editing.
â€¢	Used Excel formulas to bin age data.
â€¢	Discussed using VLOOKUP or REPLACE for bulk generalization.

â¸»

ğŸ§  Key Takeaways
â€¢	Re-identification is a real threat, even for anonymized data.
â€¢	K-anonymity provides a structured method for data privacy.
â€¢	Techniques like suppression and generalization help ensure data cannot be traced back to individuals.
â€¢	Always work from a master copy before anonymizing data.

â¸»

ğŸ“Œ Homework / Reminder
â€¢	Begin work on Position Paper 3 (anti-position paper).
â€¢	Explore anonymization techniques further by applying them to the dummy patient dataset (available on Canvas).
â€¢	Be prepared to discuss anonymization strategies on Wednesday.