# Privacy, AI, and Digital Threats in the 21st Century

**Date:** April 7, 2025  
**Course:** CIDS 120

---

## Summary

In this lecture, we continued our discussion on digital privacy in the context of artificial intelligence, facial recognition, institutional data use, and self-inflicted privacy breaches. We explored the real-world implications of AI voice cloning, unauthorized data access, phishing, identity theft, and biometric payment technologies. The lesson emphasized that privacy threats can come from governments, corporations, malicious actors, and even ourselves. Students were encouraged to think critically about their role in maintaining privacy and to reflect on emerging technologies and ethical dilemmas associated with data collection.

---

## Review of Prior Lecture

We began with a quick recap of the previous lecture's discussion on whether the deceased maintain a right to privacy. That lecture explored AI's power to reanimate individuals through deepfakes and digital avatars, examining ethical concerns surrounding likeness and consent post-mortem.

---

## Deepfakes and AI Voice Cloning

- In the 2024 U.S. election, AI-generated voice clips were used in political ads to simulate real speech.
- AI can now replicate a person’s voice from written text, raising issues of consent and deception.
- Public Service Announcement from Deutsche Telekom showed a future child warning her parents about data misuse, AI-generated scams, and the permanent consequences of digital sharing.

**Real World Example:**
- Scammers use AI to clone voices of loved ones, convincing victims to send money urgently, often pretending to be in jail or danger.

---

## Categories of Privacy Threats (From Michael Quinn’s Ethics Textbook)

### 1. **Privacy Threats from Our Own Actions**
- Oversharing on social media and connecting personal devices to the Internet (IoT).
- Examples include smart toilets, fitness trackers, and apps constantly collecting data.
- According to Warren and Brandeis, information shared publicly forfeits privacy protections.

### 2. **Institutional Use of Data**
#### Public Sector
- **Law Enforcement:** Can track, monitor, and surveil. Important for justice, but a privacy threat nonetheless.
- **Tax Collection:** Requires intimate financial disclosures.

#### Private Sector
- **Marketing & Decision-Making:** Your data is the product if you use free services.
- Example: Apple Watches may be more privacy-respecting if you pay for a subscription. Free services often monetize your data or attention.

### 3. **Unauthorized Use by Insiders**
- Includes both **intentional** (e.g., whistleblowers like Chelsea Manning or Edward Snowden) and **unintentional** breaches (e.g., clicking phishing links).
- **Phishing**: Emails or messages designed to trick users into giving up credentials.

### 4. **Information Theft**
- Includes stolen credit card numbers, identity theft, and social engineering scams.
- Users are often tricked into entering sensitive info on fake login pages.

**Example:**
- AOL data breach (2006): Search data from 650,000 users was released, anonymized by ID but reidentified quickly.

---

## The Role of the Constitution
- **Fourth Amendment**: Protection against unreasonable search and seizure.
- **Fifth Amendment**: Right to remain silent and not self-incriminate.
- Citizens can legally refuse entry or questions from law enforcement.
- Watch channels like *Audit the Audit* to better understand civil rights in practice.

---

## Biometric Identification and the Future
- Amazon and other companies are rolling out biometric payment systems (face, palm).
- Blue light filters, thumbprints, facial recognition—our physical bodies are becoming keys.
- Raises questions about surveillance, consent, and long-term digital identity.

---

## Key Quote
> "The man who is compelled to live every minute of his life among others... has been deprived of his individuality and his human dignity."  
— Former President of Rutgers University

---

## Reflection Prompt
**Think about this:** If you pass away tomorrow, would you want an AI version of you to continue communicating with your loved ones? Would it be respectful? Or a violation?

---

## Next Time
We'll explore how programmers and data scientists (i.e., *us*) ethically collect and use data on everyday people, and what obligations we hold in an increasingly surveilled world.

> See you Wednesday!

